{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this tutorial we will train a sentiment classifier on a sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Desktop/data/sentiment_analysis/training.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-fff92eddb962>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m################## Loading data file #######################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mreader_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Desktop/data/sentiment_analysis/training.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mreader_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/desktop/data/sentiment_analysis/test.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtraining_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'C:/Desktop/data/sentiment_analysis/training.csv'"
     ]
    }
   ],
   "source": [
    "################## Loading data file #######################\n",
    "reader_train = csv.reader(open('C:/Desktop/data/sentiment_analysis/training.csv','r'))\n",
    "reader_test = csv.reader(open('C:/desktop/data/sentiment_analysis/test.csv','r'))\n",
    "training_data = []\n",
    "test_data = []\n",
    "header = 1\n",
    "for row in reader_train:\n",
    "        if header==1:\n",
    "                header=0\n",
    "                continue\n",
    "        training_data.append(row)\n",
    "header=1\n",
    "for row in reader_test:\n",
    "        if header==1:\n",
    "                header=0\n",
    "                continue\n",
    "        test_data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Not Everybody loves Raymond.  The only joke here is that the idea actually found its way onto the airwaves.  In other words it\\\\'s just one joke less than a one joke program.  As with most sitcoms, it appeals to those with an intellectual development that was stopped at age 8.  Fortunately they did have the good sense to employ a laugh-track so that the audience will be signaled whenever something is broadcast that was intended to be funny. The program amounts to a scandalous waste of talent.\", 'neg']\n",
      "385 80\n"
     ]
    }
   ],
   "source": [
    "# Examples from training data\n",
    "print(training_data[0])\n",
    "print(len(training_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2759\n"
     ]
    }
   ],
   "source": [
    "#Required for Bag of words (unigram features) creation\n",
    "vocabulary = [x.lower() for tagged_sent in training_data for x in tagged_sent[0].split()]\n",
    "vocabulary = list(set(vocabulary))\n",
    "vocabulary.sort() #sorting the list\n",
    "print(len(vocabulary))\n",
    "# print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################## Extracting Features #########################\n",
    "#### Prepare a unigram feature vector based on the presence or absence of words######### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unigram_features(data,vocab):\n",
    "    fet_vec_all = []\n",
    "    for tup in data:\n",
    "        single_feat_vec = []\n",
    "        sent = tup[0].lower() #lowercasing the dataset\n",
    "        for v in vocab:\n",
    "            if sent.__contains__(v):\n",
    "                single_feat_vec.append(1)\n",
    "            else:\n",
    "                single_feat_vec.append(0)\n",
    "        fet_vec_all.append(single_feat_vec)\n",
    "    return fet_vec_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add sentiment scores from sentiwordnet, here we take the average sentiment scores of all words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_senti_wordnet_features(data):\n",
    "    fet_vec_all = []\n",
    "    for tup in data:\n",
    "        sent = tup[0].lower()\n",
    "        words = sent.split()\n",
    "        pos_score = 0\n",
    "        neg_score = 0\n",
    "        for w in words:\n",
    "            senti_synsets = swn.senti_synsets(w.lower())\n",
    "            for senti_synset in senti_synsets:\n",
    "                p = senti_synset.pos_score()\n",
    "                n = senti_synset.neg_score()\n",
    "                pos_score+=p\n",
    "                neg_score+=n\n",
    "                break #take only the first synset (Most frequent sense)\n",
    "        fet_vec_all.append([float(pos_score),float(neg_score)])\n",
    "    return fet_vec_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the two scores ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_features(featureList1,featureList2):\n",
    "    # For merging two features\n",
    "    if featureList1==[]:\n",
    "        return featureList2\n",
    "    merged = []\n",
    "    for i in range(len(featureList1)):\n",
    "        m = featureList1[i]+featureList2[i]\n",
    "        merged.append(m)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract the sentiment labels by making positive reviews as class 1 and negative reviews as class 2\n",
    "def get_lables(data):\n",
    "    labels = []\n",
    "    for tup in data:\n",
    "        if tup[1].lower()==\"neg\":\n",
    "            labels.append(-1)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_precision(prediction, actual):\n",
    "    prediction = list(prediction)\n",
    "#     correct_labels = [1  if test_gold_labels[i] == predictions[i] else 0 for i in range(len(predictions))]\n",
    "    correct_labels = [predictions[i]  for i in range(len(predictions)) if actual[i] == predictions[i]]\n",
    "    precision = float(len(correct_labels))/float(len(prediction))\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def real_time_test(classifier,vocab):\n",
    "    print(\"Enter a sentence: \")\n",
    "    inp = input()\n",
    "    inp = [[inp,0]] #Assign a dummy label 0 and format the input data\n",
    "    print(inp)\n",
    "    print(\"\\n\")\n",
    "    feat_vec_uni = get_unigram_features(inp,vocab)\n",
    "    feat_vec_swn =get_senti_wordnet_features(test_data)\n",
    "    feat_vec = merge_features(feat_vec_uni, feat_vec_swn)\n",
    "\n",
    "    predict = classifier.predict(feat_vec)\n",
    "    if predict[0]==1:\n",
    "        print(\"The sentiment expressed is: positive\")\n",
    "    else:\n",
    "        print(\"The sentiment expressed is: negative\")\n",
    "    \n",
    "#For naive bayes classifier, uncomment the next two lines\n",
    "#     predict = classifier.predict_proba(feat_vec)\n",
    "#     print(predict)\n",
    "\n",
    "#For SVM classifier, uncomment the next two lines\n",
    "#     predict = classifier.decision_function(feat_vec)\n",
    "#     print(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################# Training and Evaluation #######################\n",
    "#### Preparing training and test tuples\n",
    "#### The feature_vecor set looks like [featurevector1, featurevector2,...,featurevectorN] where each featurevectorX is a list\n",
    "#### The label set looks like [label1,label2,...,labelN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_unigram_features = get_unigram_features(training_data,vocabulary) # vocabulary extracted in the beginning\n",
    "training_swn_features = get_senti_wordnet_features(training_data)\n",
    "\n",
    "training_features = merge_features(training_unigram_features,training_swn_features)\n",
    "\n",
    "training_labels = get_lables(training_data)\n",
    "\n",
    "test_unigram_features = get_unigram_features(test_data,vocabulary)\n",
    "test_swn_features=get_senti_wordnet_features(test_data)\n",
    "test_features= merge_features(test_unigram_features,test_swn_features)\n",
    "\n",
    "test_gold_labels = get_lables(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of NB classifier is\n",
      "0.775\n",
      "Enter a sentence: \n",
      "I love movie because it is awesome.\n",
      "[['I love movie because it is awesome.', 0]]\n",
      "\n",
      "\n",
      "The sentiment expressed is: positive\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Classifier \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB().fit(training_features,training_labels) #training process\n",
    "predictions = classifier.predict(test_features)\n",
    "# print(\"Prediciton of NB classifier is \")\n",
    "# print(predictions)\n",
    "print(\"Precision of NB classifier is\")\n",
    "precision = calculate_precision(predictions,test_gold_labels)\n",
    "print(precision)\n",
    "#Real time tesing\n",
    "real_time_test(classifier,vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of linear SVM classifier is:\n",
      "Training data\t0.9584415584415584\n",
      "Test data\t0.775\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier\n",
    "#Refer to : http://scikit-learn.org/stable/modules/svm.html\n",
    "from sklearn.svm import LinearSVC\n",
    "classifier = LinearSVC(penalty='l2', C=0.01).fit(training_features,training_labels)\n",
    "predictions = classifier.predict(training_features)\n",
    "# print(\"Prediciton of linear SVM classifier is: \")\n",
    "# print(predictions)\n",
    "print(\"Precision of linear SVM classifier is:\")\n",
    "precision = calculate_precision(predictions,training_labels)\n",
    "print(\"Training data\\t\" + str(precision))\n",
    "predictions = classifier.predict(test_features)\n",
    "precision = calculate_precision(predictions,test_gold_labels)\n",
    "print(\"Test data\\t\" + str(precision))\n",
    "\n",
    "# print(classifier.C)\n",
    "\n",
    "#Real time tesing\n",
    "# real_time_test(classifier,vocabulary)\n",
    "# print(len(training_features[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of Decision Tree classifier is:\n",
      "Training data\t1.0\n",
      "Test data\t0.7\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(random_state=0).fit(training_features,training_labels)\n",
    "predictions = classifier.predict(training_features)\n",
    "# print(\"Prediciton of Decision Tree classifier is: \")\n",
    "# print(predictions)\n",
    "print(\"Precision of Decision Tree classifier is:\")\n",
    "precision = calculate_precision(predictions,training_labels)\n",
    "print(\"Training data\\t\" + str(precision))\n",
    "predictions = classifier.predict(test_features)\n",
    "precision = calculate_precision(predictions,test_gold_labels)\n",
    "print(\"Test data\\t\" + str(precision))\n",
    "# Real time tesing\n",
    "# real_time_test(classifier,vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
